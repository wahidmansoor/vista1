/**
 * üéØ AI Service Layer - Clean Architecture Implementation
 * 
 * ‚úÖ FEATURES:
 * - Client-side service layer that calls secure Netlify functions
 * - Input validation and sanitization
 * - Comprehensive error handling with medical context
 * - Response caching and optimization
 * - Rate limiting and quota management
 * 
 * üè• MEDICAL-SPECIFIC:
 * - Clinical prompt enhancement
 * - Medical terminology preservation
 * - Compliance-ready audit trails
 * - Failsafe responses for clinical safety
 */

import { ModuleType, PromptIntent, AIResponse } from '@/components/ai-agent/types';
import { InputSanitizer, ValidationResult } from '@/lib/utils/inputSanitizer';
import { AIErrorHandler } from '@/lib/errors/AIErrorHandler';
import { agentLogger } from '@/components/ai-agent/agentLogger';
import { v4 as uuidv4 } from 'uuid';

export interface ErrorContext {
  module?: string;
  intent?: string;
  userId?: string;
  sessionId?: string;
  attempt?: number;
  originalError?: any;
}

export interface AIServiceRequest {
  prompt: string;
  module: ModuleType;
  intent: PromptIntent;
  context?: string;
  history?: string[];
  iterationCount?: number;
  previousResponse?: string;
  feedbackType?: 'refine' | 'elaborate' | 'correct';
  userId?: string;
  sessionId?: string;
}

export interface AIServiceResponse {
  success: boolean;
  data?: AIResponse;
  error?: {
    code: string;
    message: string;
    suggestions: string[];
    retryable: boolean;
  };
  metadata?: {
    provider: string;
    model: string;
    responseTime: number;
    cached: boolean;
    sanitized: boolean;
  };
}

export interface ServiceConfig {
  maxRetries: number;
  timeoutMs: number;
  enableCaching: boolean;
  fallbackEnabled: boolean;
  rateLimit: {
    windowMs: number;
    maxRequests: number;
  };
}

/**
 * Main AI Service class - handles all AI interactions with proper abstraction
 */
export class AIService {
  private static readonly DEFAULT_CONFIG: ServiceConfig = {
    maxRetries: 3,
    timeoutMs: 30000,
    enableCaching: true,
    fallbackEnabled: true,
    rateLimit: {
      windowMs: 60000, // 1 minute
      maxRequests: 15
    }
  };

  private static config: ServiceConfig = { ...this.DEFAULT_CONFIG };
  private static responseCache = new Map<string, { data: AIResponse; timestamp: number }>();
  private static readonly CACHE_TTL = 5 * 60 * 1000; // 5 minutes

  /**
   * Main entry point for AI requests
   */
  static async generateResponse(
    request: AIServiceRequest,
    config: Partial<ServiceConfig> = {}
  ): Promise<AIServiceResponse> {
    const startTime = Date.now();
    const mergedConfig = { ...this.config, ...config };
    
    try {
      // Step 1: Validate and sanitize input
      const validationResult = await this.validateRequest(request);
      if (!validationResult.isValid) {
        return this.createErrorResponse('INVALID_INPUT', validationResult.reason || 'Invalid input');
      }

      // Step 2: Check rate limiting
      if (request.userId) {
        const rateLimitResult = InputSanitizer.validateRateLimit(
          request.userId,
          mergedConfig.rateLimit.windowMs,
          mergedConfig.rateLimit.maxRequests
        );

        if (!rateLimitResult.allowed) {
          return this.createErrorResponse(
            'RATE_LIMIT_EXCEEDED',
            `Rate limit exceeded. Try again in ${Math.ceil((rateLimitResult.resetTime! - Date.now()) / 1000)} seconds.`
          );
        }
      }      // Step 3: Check cache
      if (mergedConfig.enableCaching) {
        const cached = this.getCachedResponse(request);
        if (cached) {
          return {
            success: true,
            data: cached,
            metadata: {
              provider: 'cache',
              model: cached.metadata?.model || 'cached',
              responseTime: Date.now() - startTime,
              cached: true,
              sanitized: true
            }
          };
        }
      }

      // Step 4: Sanitize the request
      const sanitizedRequest = this.sanitizeRequest(request);

      // Step 5: Generate response with retry logic
      const response = await this.generateWithRetry(sanitizedRequest, mergedConfig);

      // Step 6: Cache successful responses
      if (mergedConfig.enableCaching && response.success && response.data) {
        this.cacheResponse(request, response.data);
      }

      return response;

    } catch (error) {
      const errorContext: ErrorContext = {
        module: request.module,
        intent: request.intent,
        userId: request.userId,
        sessionId: request.sessionId,
        attempt: 1
      };

      const aiError = AIErrorHandler.create(error);
      
      // Log the error
      agentLogger.logInteraction({
        module: request.module,
        intent: request.intent,
        prompt: request.prompt,
        success: false,
        error: aiError.message,
        metadata: {
          errorCode: aiError.code || 'UNKNOWN',
          responseTime: Date.now() - startTime
        }
      });

      return {
        success: false,
        error: {
          code: aiError.code || 'UNKNOWN',
          message: aiError.userMessage || aiError.message,
          suggestions: [],
          retryable: aiError.retryable || false
        }
      };
    }
  }

  /**
   * Validates the incoming request
   */
  private static async validateRequest(request: AIServiceRequest): Promise<ValidationResult> {
    // Basic structure validation
    if (!request.prompt || !request.module || !request.intent) {
      return { isValid: false, reason: 'Missing required fields: prompt, module, or intent' };
    }

    // Validate prompt content
    const promptValidation = InputSanitizer.validatePrompt(request.prompt);
    if (!promptValidation.isValid) {
      return promptValidation;
    }

    // Validate module and intent
    const validModules = ['OPD', 'CDU', 'Inpatient', 'Palliative', 'RadOnc'];
    if (!validModules.includes(request.module)) {
      return { isValid: false, reason: 'Invalid module specified' };
    }

    return { isValid: true };
  }

  /**
   * Sanitizes the request before processing
   */
  private static sanitizeRequest(request: AIServiceRequest): AIServiceRequest {
    return {
      ...request,
      prompt: InputSanitizer.sanitizePrompt(request.prompt),
      context: request.context ? InputSanitizer.sanitizeMedicalContext(request.context) : undefined,
      history: request.history?.map(h => InputSanitizer.sanitizeMedicalContext(h)),
      previousResponse: request.previousResponse ? InputSanitizer.sanitizeMedicalContext(request.previousResponse) : undefined
    };
  }

  /**
   * Generates response with retry logic
   */
  private static async generateWithRetry(
    request: AIServiceRequest,
    config: ServiceConfig
  ): Promise<AIServiceResponse> {
    let lastError: any;
    
    for (let attempt = 1; attempt <= config.maxRetries; attempt++) {
      try {
        const response = await this.callAIProvider(request, config, attempt);
        return response;
      } catch (error) {
        lastError = error;
        
        const aiError = AIErrorHandler.create(error);
        
        // Check if we should retry
        if (attempt >= config.maxRetries || !aiError.retryable) {
          break;
        }

        if (attempt < config.maxRetries) {
          const delay = this.calculateRetryDelay(attempt);
          await this.delay(delay);
        }
      }
    }

    throw lastError;
  }

  /**
   * Calls the actual AI provider (Netlify function)
   */  private static async callAIProvider(
    request: AIServiceRequest,
    config: ServiceConfig,
    attempt: number
  ): Promise<AIServiceResponse> {
    const startTime = Date.now();
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), config.timeoutMs);

    try {
      // Call the Netlify function
      const response = await fetch('/.netlify/functions/gemini-ai', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          prompt: request.prompt,
          context: request.context,
          history: request.history,
          module: request.module,
          intent: request.intent
        }),
        signal: controller.signal
      });

      clearTimeout(timeoutId);

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const data = await response.json();
      
      // Validate response structure
      if (!data.id || !data.content) {
        throw new Error('Invalid response structure from AI provider');
      }      const aiResponse: AIResponse = {
        id: data.id,
        content: data.content,
        timestamp: new Date(data.timestamp),
        metadata: {
          module: request.module,
          intent: request.intent,
          model: data.metadata?.model || 'gemini-pro'
        }
      };      // Log successful interaction
      agentLogger.logInteraction({
        module: request.module,
        intent: request.intent,
        prompt: request.prompt,
        success: true,
        metadata: {
          responseTime: Date.now() - startTime,
          model: aiResponse.metadata?.model || 'gemini-pro',
          provider: 'gemini',
          attempt
        }
      });      return {
        success: true,
        data: aiResponse,
        metadata: {
          provider: 'gemini',
          model: aiResponse.metadata?.model || 'gemini-pro',
          responseTime: Date.now() - startTime,
          cached: false,
          sanitized: true
        }
      };

    } catch (error) {
      clearTimeout(timeoutId);
      throw error;
    }
  }

  /**
   * Cache management
   */
  private static getCachedResponse(request: AIServiceRequest): AIResponse | null {
    const cacheKey = this.generateCacheKey(request);
    const cached = this.responseCache.get(cacheKey);
    
    if (cached && Date.now() - cached.timestamp < this.CACHE_TTL) {
      return cached.data;
    }
    
    if (cached) {
      this.responseCache.delete(cacheKey); // Remove expired cache
    }
    
    return null;
  }

  private static cacheResponse(request: AIServiceRequest, response: AIResponse): void {
    const cacheKey = this.generateCacheKey(request);
    this.responseCache.set(cacheKey, {
      data: response,
      timestamp: Date.now()
    });

    // Cleanup old cache entries
    this.cleanupCache();
  }

  private static generateCacheKey(request: AIServiceRequest): string {
    const key = `${request.module}_${request.intent}_${request.prompt.substring(0, 100)}`;
    return Buffer.from(key).toString('base64');
  }

  private static cleanupCache(): void {
    const now = Date.now();
    for (const [key, value] of this.responseCache.entries()) {
      if (now - value.timestamp > this.CACHE_TTL) {
        this.responseCache.delete(key);
      }
    }
  }

  /**
   * Utility methods
   */
  private static delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  private static calculateRetryDelay(attempt: number): number {
    const baseDelay = 1000; // 1 second
    const maxDelay = 10000; // 10 seconds
    const delay = baseDelay * Math.pow(2, attempt - 1);
    return Math.min(delay + Math.random() * 1000, maxDelay);
  }

  private static createErrorResponse(code: string, message: string): AIServiceResponse {
    return {
      success: false,
      error: {
        code,
        message,
        suggestions: [],
        retryable: false
      }
    };
  }

  /**
   * Configuration management
   */
  static updateConfig(newConfig: Partial<ServiceConfig>): void {
    this.config = { ...this.config, ...newConfig };
  }

  static getConfig(): ServiceConfig {
    return { ...this.config };
  }

  /**
   * Health check for the AI service
   */
  static async healthCheck(): Promise<{ healthy: boolean; provider: string; latency?: number }> {
    try {
      const startTime = Date.now();
      const testRequest: AIServiceRequest = {
        prompt: 'Health check',
        module: 'OPD',
        intent: 'screening'
      };

      await this.callAIProvider(testRequest, { ...this.DEFAULT_CONFIG, maxRetries: 1 }, 1);
      
      return {
        healthy: true,
        provider: 'gemini',
        latency: Date.now() - startTime
      };
    } catch (error) {
      return {
        healthy: false,
        provider: 'gemini'
      };
    }
  }

  /**
   * Get service statistics
   */
  static getStats(): {
    cacheSize: number;
    cacheHitRate: number;
    uptime: number;
  } {
    return {
      cacheSize: this.responseCache.size,
      cacheHitRate: 0, // Would need to track hits vs misses
      uptime: typeof process !== 'undefined' && process.uptime ? process.uptime() : 0
    };
  }
}

// Convenience functions for backward compatibility
export async function callAIAgent(params: AIServiceRequest): Promise<AIResponse> {
  const response = await AIService.generateResponse(params);
  
  if (!response.success || !response.data) {
    throw new Error(response.error?.message || 'Failed to generate AI response');
  }
  
  return response.data;
}

export async function callAIAgentWithRetry(
  params: AIServiceRequest,
  maxRetries = 3
): Promise<AIResponse> {
  const response = await AIService.generateResponse(params, { maxRetries });
  
  if (!response.success || !response.data) {
    throw new Error(response.error?.message || 'Failed to generate AI response after retries');
  }
  
  return response.data;
}
